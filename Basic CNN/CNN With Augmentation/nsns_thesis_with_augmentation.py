# -*- coding: utf-8 -*-
"""NSNS Thesis With Augmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-q5hyZtXFzyyTNVQ0IOkmOXYU-hnNNIr

***
**Importing necessary libraries**
***
"""

import numpy as np
import os
from sklearn.metrics import confusion_matrix
import seaborn as sn; sn.set(font_scale=1.4)
from sklearn.utils import shuffle           
import matplotlib.pyplot as plt             
import cv2                                 
import tensorflow as tf                
from tqdm import tqdm

"""***
**Merging Google Drive**
***
"""

from google.colab import drive
drive.mount('/content/drive')

"""***
**Dataset Path**
***
"""

dataset='/content/drive/MyDrive/BRAC /Past Courses/Thesis/Pre Thesis II/Final Paper of Pre Thesis II/14- Used Dataset/Sorted Data/Image Version'

"""***
**Installing and importing mne for reading EEG data**
***
"""

!pip install mne

import mne

"""***
**Creating Classes**
***

"""

class_names = ['Healthy', 'MDD']
class_names_label = {class_name:i for i, class_name in enumerate(class_names)}

"""***
**Data Preprocessing**
***
"""

images = []
labels = []
output=[]
IMAGE_SIZE = (150, 150)
print("Loading {}".format(dataset))

# Iterate through each folder corresponding to a category
for folder in os.listdir(dataset):
    label = class_names_label[folder]
    
    # Iterate through each image in our folder
    for file in tqdm(os.listdir(os.path.join(dataset, folder))):
        
        # Get the path name of the image
        img_path = os.path.join(os.path.join(dataset, folder), file)

        # Open and resize the img
        image = cv2.imread(img_path)
        image = image[6:208,92:420]
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, IMAGE_SIZE) 
        
        # Append the image and its corresponding label to the output
        images.append(image)
        labels.append(label)

images = np.array(images, dtype = 'float32')
labels = np.array(labels, dtype = 'int32')

output.append((images, labels))

import numpy as np
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

"""***
**Creating the 2D CNN model**
***
"""

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), 
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(2, activation=tf.nn.softmax)
])

"""***
**Accuracy Level**
***
"""

model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])

"""***
**Data Training**
***
"""

history = model.fit(X_test, y_test, batch_size=5, epochs=20)

"""***
**Prediction**
***
"""

predictions = model.predict(X_test)     # Vector of probabilities
pred_labels = np.argmax(predictions, axis = 1) # We take the highest probability